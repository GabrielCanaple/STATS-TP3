---
title: "TP Statistiques"
author: "Gabriel CANAPLE, BOYER THOMAS, LECLUSE Martin, FAYALA Mohamed"
date: "19 Janvier 2024"
output:
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: 80
---

(décrire la régression, l'état des résidus, le test de normalité, est-elle
centrée, variance est constante ? indépendance ?) test de shapiro, student, chi2
régression linéaire = chap 6 du cours y = ax + b + epsilon y = variable
expliquée a, b = inconnues x = variable explicative epsilon = résidus test de
pertinence : a=0? test de biais : b=0?

on peut aussi avoir plusieurs variables explicatives : y = a1*x1 + a2*x2 + ... +
an\*xn + epsilon

PENSER A définir le risque alpha pour chacun des tests (si on sait pas quoi
prendre prendre 5%)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## il est possible qu'avant d'installer le package TSPpackage vous deviez installer ou ré-installer Rcpp
#install.packages('Rcpp')

# install.packages('./TSPpackage_1.0.tar.gz',repos=NULL,type='bin') ## pour linux
# install.packages('./TSPpackage_1.0.zip',repos=NULL,type='bin')    ## pour windows
## je ne peux pas fournir de package pour mac...

## Appels aux packages, après les avoir installés !
library(sp)
library(maps)
library(microbenchmark)
library(TSP)
library(TSPpackage)
set.seed(35)
```

# Introduction

L'objectif du TP est de comparer les performances d'algorithmes de calcul de circuit hamiltonien dans un graphe, selon les critères de longueur du chemin, et de temps d'exécution.

Nos conclusions se basent tout au long du TP sur les méthodes statistiques aabordées en cours : test d'hypothèse, tests multiples, régression linéaire.

Dans une première partie, nous montrerons une visualisation du problème résolu par les algorithmes, puis nous comparerons ces derniers sur le critère de la longueur du chemin hamiltonien trouvé, et ensuite sur le temps d'exécution. Enfin, nous essayerons de proposer une régression linéaire de la complexité de l'algorithme Branch & Bound.

# 1. Visualisation de chemins

Voici les données présentes dans le fichier "DonneesGPSvilles.csv" :

```{r, echo=TRUE}
set.seed(35)
villes <- read.csv('DonneesGPSvilles.csv',header=TRUE,dec='.',sep=';',quote="\"")
str(villes)
```

Et voici comment nous visualisaons les résultats données par les algorithmes (ici, avec l'exemple de l'algorithme "nearest", comaré au chemin optimal fourni) :

```{r, echo=TRUE}
set.seed(35)
coord <- cbind(villes$longitude,villes$latitude)
dist <- distanceGPS(coord)
voisins <- TSPnearest(dist)

pathOpt <- c(1,8,9,4,21,13,7,10,3,17,16,20,6,19,15,18,11,5,22,14,12,2)

par(mfrow=c(1,2),mar=c(1,1,2,1))
plotTrace(coord[voisins$chemin,], title='Nearest')
plotTrace(coord[pathOpt,], title='Chemin optimal')
```

Le total de la longueurs des trajets (à vol d'oiseau) valent respectivement, pour la méthode des plus proches voisins :

```{r, echo=FALSE}
set.seed(35)
voisins$longueur
```

et pour la méthode optimale :

```{r, echo=FALSE}
set.seed(35)
calculeLongueur(dist,pathOpt)
```

On remarque que le résultat de l'algorithme est peu performant, avec de incohérences que l'on peut facilement voir sur la carte, et qui sont confirmées par le total de la longueur des chemins.

Cela illustre l'intérêt de notre démarche : il faut pouvoir objectifier la performance des algorithmes pour les comparer entre eux, et sélectionner le meilleur (selon certains critères).

C'est l'objet des parties suivantes.

# 2. Comparaison d'algorithmes

On fixe le nombre de somets du graphe à 10. Les coordonnées cartésiennes sont des lois uniformes sur [0,1] :

```{r, echo=TRUE}
set.seed(35)
n <- 10 #nombre de noeuds

#exemple de lancement unitaire
sommets <- data.frame(x = runif(n), y = runif(n))
couts <- distance(sommets)
TSPsolve(dist,'nearest') #LE RESULTAT ICI ME PARAIT BIZARRE (4000 alors que ya que des coordonnées entre 0 et 1, on est surs qu'on l'appelle avec le bon jeu de données ?)
```

On lance 50 simulations par algorithme, ce qui donne le résultat suivant (premières lignes uniquement) :
```{r, echo=FALSE}
set.seed(35)

#calcul de plusieurs simulations de graphes qui seront analysées par les 5 méthodes
nsimu <- 50 #nombre de simu
methods <- c('arbitrary_insertion', 'repetitive_nn','two_opt','nearest','branch')
res <- array(0,dim=c(nsimu,length(methods)))

for(i in 1:nsimu){
  points <- data.frame(x = runif(n), y = runif(n))
  dist <- distance(points)
  res[i,] <- (sapply(methods, function(m){TSPsolve(dist,m)}))
}

colnames(res) <- c('insertion','repet_nn','two_opt','nearest','branch')
res[1:5] #AFFICHER 5 PREMIERES LIGNES : A VERIFIER
```

### 2.1. Longueur des chemins

On s'intéresse ici à la longueur des chemins retournée par chacun des méthodes. Notre but est de détermnier quel(s) algorithme(s) est le plus performant selon ce critère, c'est-à-dire renvoie une longueur la plus faible possible.
Pour répondre à cette question, on visualisera d'abord les résultats, avant de mener des études plus approfondies, d'abord sur les algorithmes "nearest" et "branch & bound", puis entre tous les algortihmes 2 à 2.

### Observation des résultats

Voici d'abord une visualisation des résultats sous forme de boxplot :
```{r, echo=TRUE}
set.seed(35)
res2 <- as.vector(res)
meth_names <- c('insertion','repetitive_nn','two_opt','nearest','branch')
methods2 <- rep(meth_names,each=nsimu) 

boxplot(res,
        main="Résultats des algorithmes de calcul de circuit hamiltonien",
        xlab="Algorithmes",
        ylab="Longueur des chemins")
```

On observe des différences entre les résultats des algorithmes. Celles-ci sont a priori assez failbes, puisque les espaces interquartiles se chevauchent tous (cela est sûrement du aux petits écrats entre les coordonnées). La moyenne de la longuer des chemins est comprise entre 2.8 et 3.0 pour tous.
Il semble tout de même que "insertion", "repet_nn" et "branch" aient des résultats très similaires, alors que "two_opt" et "nearest" se démarquent du reste, avec des résultats un peu plus élevés.
Au sujet de la variance, on observe que "repet_nn" semble avoir une valeur faible, avec des résultats des 1er et 9e déciles plus proche de la moyenne que pour les autres algorithmes. "nearest", "insertion, "two_opt" au contraire paraissent avoir une variance plus élevée. Concernant "branch", la dispersion des valeurs semblent surtout être vraie pour lse valeurs faibles : le 9e décile est assez peu supérieur à la moyenne, alors que le 1er décile y est très inférieur.

### Test de normalité

Afin de vérifier si l'on peut faire des tests de Student avec les résultats obtenus, nous vérifions qu'il satisfont tous l'hypothèse de normalité avec un test de Shapiro :

``` {r echo = TRUE}
shapiro.test(res[,1])
shapiro.test(res[,2])
shapiro.test(res[,3])
shapiro.test(res[,4])
shapiro.test(res[,5])
```

Avec un seuil de risque à 5%, on ne rejette pas l'hypothèse de normalité pour toutes les distributions. On peut donc faire des tests de Student sur ces résultats.

### Comparaison de "nearest" et de "branch & bound"

Notre premier objectif est de comparer les performances de "nearest" et de "branch & bound". En effet, ce sont les algorithmes qui ont a priori le plus de chances d'être significativement différents (cf boxplot).

On cherche à savoir si "nearest" est significativement moins performant que "branch & bound", donc on pose les hypothèse suivantes $H(0) : m_n - m_bb <= 0$ et $H(1) : m_n-m_bb > 0$. De cette manière, on contrôle le risque de conclure que "nearest" est meilleur que "branch & bound" alors que ce n'est pas le cas. A noter que, ici, l'algorithme le plus performant trouve une longueur plus faible.

Pour ce test, on prend un seuil de risque de 5%.

Précisons également que la soustraction $m_n _ m_bb$ est faite car nous avons ici des calculs faits sur le même échantillon, et qu'elle nous peremt de limiter les incertitudes : en effet, on construit une troisième gaussienne (la différence des deux premières), que l'on compare à une valeur constante, plutôt que de comparer deux gaussiennes entre elles.

```{r echo=TRUE}
nearest_branch <- res[,4] - res[,5]
t.test(res[,4], res[,5], alternative = "greater")
```

Avec une p-valeur de 0.00005%, on conclut qu'on rejette l'hypothèse nulle, et que $m_n$ est significativement moins performant que $m_bb$. De plus, la très faible p-valeur nous donne une grande confiance dans ce résultat.

### Tests deux à deux

L'objectif de cette analyse est de déterminer si l'on peut regrouper les différents algorithmes par performance sur le critère de longueur des chemins trouvés. Cela permettra de présenter les résultats sous une forme plus intelligible, et éventuellement de faire plus tard des choix entre les algorithmes pus facilement (en prenant d'autres critères comme le temps d'exécution par exemple).

```{r echo=TRUE}
result <- pairwise.t.test(res2,methods2, p.adjust.method = "bonferroni")
result
```

Nous prenons un risque $\alpha$ égal à 5%.
La seule différence notable est entre nearest et branch, avec une p-valeur inférieure à 5%.
Nous avons choisi de répartir les algorithmes entre 4 groupes :
- Le premier groupe est composé d'insertion, et de repetitive-nn.
- Le deuxième groupe se constitue de nearest.
- Le troisième groupe contient two-opt.
- Le quatrième groupe contient branch and bound
La philosophie de cette répartition est de rassembler les algorithmes similaires entre eux, et ayant des différences avec les même algorithmes. A compléter.

## 2.2. Temps de calcul

Après avoir étudié les performances des algorithmes selon la longueur des chemins trouvés, nous étudions les performances en termes de temps de calcul.

On exécute les algorithmes 20 fois, les coordonnées des points sont comme précédemment générés par une lois uniforme sur [0,1].

On utilise pour cela le package "microbenchmark" :

```{r, echo=TRUE}
set.seed(35)

microbenchmark::microbenchmark(TSPsolve(jeuDeDonnees, method=methods[1]),TSPsolve(jeuDeDonnees, method=methods[2]), TSPsolve(jeuDeDonnees, method=methods[3]), TSPsolve(jeuDeDonnees, method=methods[4]), TSPsolve(jeuDeDonnees, method=methods[5]), times=20, setup={jeuDeDonnees <- distance(data.frame(x = runif(n), y = runif(n)))})
```

Les lignes correspondent dans l'ordre à : "insertion", "repet_nn", "two_opt", "nearest" et "branch".

Les résultat permettent de séparer les algorithmes en 2 classe :
 - "insertion", "two_opt" et "nearest" : exécution plus rapide, avec une moyenne comprise entre 7 et 260 microsecondes
 - "repet_nn" et "branch & bound" : exécution plus lente, avec une moyenne supérieur à 2200 microsecondes
 
Si l'on compare avec les résultats de la partie précédente, et la longuer des chemins, on

# 2. Etude de la complexité de l'algorithme Branch and Bound

Dans cette partie, on étudie la complexité de Branch & Bound, en étudiant le temps d'exécution en fonction de la taille du graphe.

## 2.1. Comportement par rapport au nombre de sommets : premier modèle

On crée à chaque fois 10 graphes, pour des valeurs de $n$ entre 4 et 20 inclus. Comme précédemment, on généère les coordonnées des points avec une loi uniforme sur [0,1] :

```{r, echo=TRUE}
set.seed(35)
sommets <- data.frame(x = runif(n), y = runif(n))
couts <- distance(sommets)
```

Nous construisons un modèle de régression linéaire simple du temps d’exécution de Branch&Bound en fonction
du nombre de sommets n.
Introduisons

```{r, echo=TRUE}
set.seed(35)
seqn <- seq(4,20,1)
```

On construit la matrice des résultats :

```{r, echo=TRUE}
set.seed(35)
temps  <- matrix(nrow = length(seqn), ncol=10)
for (i in 1:17) {
  temps[i,] = 
  microbenchmark(TSPsolve(couts, method = 'branch'),
  times = 10,
  setup = { n <- seqn[i]
  couts <- distance(cbind(x = runif(n), y = runif(n))) }
  )$time
}
```

Et on affiche les résultats sur un graphe. Les premiers résultats nous laissant penser à une relations de forme $exp(n/2)$, on affiche aussi $\log(temps)^2$ :

```{r, echo=TRUE}
set.seed(35)
par(mfrow=c(1,2)) # 2 graphiques sur 1 ligne
matplot(seqn, temps, xlab='n', ylab='temps')
matplot(seqn, log(temps)^2, xlab='n', ylab=expression(log(temps)^2))
```

L'observation des résultats nous permet de suspecter une relation linéaire, même si le deuxième graphe montre une relation qui semble légèrement logarithmique.

On crée le modèle de régression linéaire de $\log(temps)^2$ en fonction de $n$ :
```{r, echo=TRUE}
set.seed(35)
vect_temps <- log(as.vector(temps))^2
vect_dim <- rep(seqn, times=10)
temps.lm <- lm(vect_temps ~ vect_dim)
summary(temps.lm)
```

### Test de pertinence
Ici, la p-valeur de l'hypothèse $a=0$ (ligne vect_dim) est extrêmement inférieure à 5%, ainsi, l'hypothèse $a=0$ est rejetée avec une grande confiance. Le modèle linéaire est pertinent.

### Etude du biais
Ici, la p-valeur de l'hypothèse $b=0$ (ligne vect_dim) est extrêmement inférieure à 5%, ainsi, l'hypothèse $b=0$ est rejetée avec une grande confiance : il y a un biais dans la relation.

### Etude des résidus
#### Test de normalité

Comme précédemment, le test de normalité est per le test de Shapiro, avec un seuil de risque de 5% :
```{r}
shapiro.test(residuals(temps.lm))
```

On obtient une p-valeur = 0.37 > 5%. On ne rejette pas l'hypothèse de normalité : les résidus suivent une loi normale.

##### Etude graphique
```{r}
par(mfrow=c(1,2)) # 4 graphiques sur 2 lignes et 2 colonnes
plot(temps.lm)
```
Résiduals vs Fitted : la courbe n'est ni horizontale ni homogène. 
Normal Q-Q : L'ensemble des points sont sur la diagonale avec quelques exceptions (points 135 et 46). On peut en désuire que les résidus suivent une loi normale  
Scale location : courbe moins concave que Résiduals vs Fitted mais toujour pas horizontale
Residuals vs Leverage : les points sont éloignés de la distance de Cook = 1

##### Tests

#### Test d'espérance
##### Etude graphique

##### Tests

#### Test de variance
##### Etude graphique

##### Tests

#### Test d'indépendance
##### Etude graphique

## 2.2. Comportement par rapport au nombre de sommets : étude du comportement moyen

Récupération du temps moyen.

Ajustement du modèle linéaire de $\log(temps.moy)^2$ en fonction de $n$.
```{r}
temps.moy <- rowMeans(temps)
matplot(seqn, log(temps.moy)^2, xlab='n', ylab=expression(log(temps.moy)^2))
```


Analyse de la validité du modèle :

-   pertinence des coefficients et du modèle,
```{r}
vect_moy <- log(as.vector(temps.moy))^2
vect_dim_moy <- rep(seqn)
temps.moy.lm <- lm(vect_dim_moy ~ vect_moy)
summary(temps.moy.lm)
```
-   étude des hypothèses sur les résidus.
```{r}
par(mfrow=c(1,2)) # 4 graphiques sur 2 lignes et 2 colonnes
plot(temps.moy.lm)
```

```{r}
shapiro.test(residuals(temps.moy.lm))
```

## 2.3. Comportement par rapport à la structure du graphe

Lecture du fichier 'DonneesTSP.csv'.

```{r,echo=TRUE}
data.graph <- read.csv(file='DonneesTSP.csv',header=TRUE)
str(data.graph)
```

Ajustement du modèle linéaire de $\log(temps.moy)^2$ en fonction de toutes les
variables présentes. Modèle sans constante.

```{r,echo=TRUE}
data.graph$log.tps <- log(data.graph$tps)#log(donnees$tps)^2
data.graph$sqrt.dim <- sqrt(data.graph$dim)
data.graph$tps <- c() #on retire les variables tps et dim devenues inutiles
data.graph$dim <- c()
str(data.graph)
```

```{r}

modele.complet = lm(data.graph$log.tps~., data = data.graph)
```

Mise en \oe uvre d'une sélection de variables pour ne garder que les variables
pertinentes.

Analyse de la validité du modèle :
```{r}
step(modele.complet)
```
-   pertinence des coefficients et du modèle,

-   étude des hypothèses sur les résidus.
```{r}
par(mfrow=c(1,2)) # 4 graphiques sur 2 lignes et 2 colonnes
plot(modele.complet)
```

```{r}
shapiro.test(residuals(modele.complet))
```